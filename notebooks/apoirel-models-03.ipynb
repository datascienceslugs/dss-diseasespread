{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iterations on the baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Anders Poirel - 13-02-20120*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals:\n",
    "- build seperate models by city\n",
    "- drop correlated features\n",
    "- observe the results from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import (cross_validate, TimeSeriesSplit, \n",
    "                                     RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_o = pd.read_csv(join(DATA_PATH, 'dengue_features_test.csv'))\n",
    "X_train_o = pd.read_csv(join(DATA_PATH, 'dengue_features_train.csv'))\n",
    "y_train_o = pd.read_csv(join(DATA_PATH, 'dengue_labels_train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train_o, columns = ['city'], drop_first = True)\n",
    "X_test = pd.get_dummies(X_test_o, columns = ['city'], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unecessary / correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('week_start_date', axis = 1, inplace = True)\n",
    "X_test.drop('week_start_date', axis = 1, inplace = True)\n",
    "y_train = y_train_o['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(\n",
    "    ['reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_k',\n",
    "     'reanalysis_tdtr_k'],\n",
    "    axis = 1, \n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(\n",
    "    ['reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_k',\n",
    "     'reanalysis_tdtr_k'],\n",
    "    axis = 1, \n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iq = X_train[X_train['city_sj'] == 0]\n",
    "X_test_iq = X_test[X_test['city_sj'] == 0]\n",
    "\n",
    "X_train_sj = X_train[X_train['city_sj'] == 1]\n",
    "X_test_sj = X_test[X_test['city_sj'] == 1]\n",
    "\n",
    "y_train_sj = y_train_o[y_train_o['city'] == 'sj']['total_cases']\n",
    "y_train_iq =  y_train_o[y_train_o['city'] == 'iq']['total_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of San Jose instances to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_ratio = len(y_train_sj) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model w/o city separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.7426637592478"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('ridge', Ridge(1400))\n",
    "])\n",
    "ridge_res = cross_validate(\n",
    "    estimator = ridge,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "ridge_score = np.mean(ridge_res['test_score'])\n",
    "ridge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge seems to like high penalties. Cranking up $\\alpha$ to 1400 decreade MAE from 35 to ~25.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try LASSO to see if feature selection is more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.9878546196094"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('lasso', Lasso(6.65))\n",
    "])\n",
    "lasso_res = cross_validate(\n",
    "    estimator = lasso,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "lasso_score = np.mean(lasso_res['test_score'])\n",
    "lasso_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to be having difficulties getting under 28 MAE with the LASSO. Try ElasticNet now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.582635929294337"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('en', ElasticNet(5))\n",
    "])\n",
    "en_res = cross_validate(\n",
    "    estimator = en,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "en_score = np.mean(en_res['test_score'])\n",
    "en_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't seem to improve on ElasticNet, so we try a polynomial kernel with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.94206254674812"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgep = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('poly_f', PolynomialFeatures(degree = 2)),\n",
    "    ('ridge', Ridge(5600))\n",
    "])\n",
    "ridgep_res = cross_validate(\n",
    "    estimator = ridgep,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "ridgep_score = np.mean(ridgep_res['test_score'])\n",
    "ridgep_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still doesn't beat elasticnet with polynomial features in `models-02`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.58044699431419"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enp = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('poly_f', PolynomialFeatures(degree = 2)),\n",
    "    ('en', ElasticNet(5))\n",
    "])\n",
    "enp_res = cross_validate(\n",
    "    estimator = enp,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "enp_score = np.mean(enp_res['test_score'])\n",
    "enp_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STILL no improvement. Let's move on to separating by city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with city separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32.890977114750974"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sj = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('en', ElasticNet(7))\n",
    "])\n",
    "en_sj_res = cross_validate(\n",
    "    estimator = en_sj,\n",
    "    X = X_train_sj,\n",
    "    y = y_train_sj,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "en_score_sj = np.mean(en_sj_res['test_score'])\n",
    "en_score_sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.430553285279375"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_iq = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('en', ElasticNet(5.5))\n",
    "])\n",
    "en_iq_res = cross_validate(\n",
    "    estimator = en_iq,\n",
    "    X = X_train_iq,\n",
    "    y = y_train_iq,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "en_score_iq = np.mean(en_iq_res['test_score'])\n",
    "en_score_iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.44082574708255"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tot_score = sj_ratio * en_score_sj + (1 - sj_ratio) * en_score_iq\n",
    "en_tot_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if a polynomial kernel improves this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32.80471491375509"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_sj = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('poly_f', PolynomialFeatures(2)),\n",
    "    ('en', ElasticNet(14))\n",
    "])\n",
    "poly_sj_res = cross_validate(\n",
    "    estimator = poly_sj,\n",
    "    X = X_train_sj,\n",
    "    y = y_train_sj,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "poly_score_sj = np.mean(poly_sj_res['test_score'])\n",
    "poly_score_sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.176574691549268"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_iq = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute_m', SimpleImputer()),\n",
    "    ('poly_f', PolynomialFeatures(2)),\n",
    "    ('en', ElasticNet(2))\n",
    "])\n",
    "poly_iq_res = cross_validate(\n",
    "    estimator = poly_iq,\n",
    "    X = X_train_iq,\n",
    "    y = y_train_iq,\n",
    "    cv = TimeSeriesSplit(n_splits = 10),\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = -1\n",
    ")\n",
    "poly_score_iq = np.mean(poly_iq_res['test_score'])\n",
    "poly_score_iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.65180769153873"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_tot_score = sj_ratio * poly_score_sj + (1 - sj_ratio) * poly_score_iq\n",
    "poly_tot_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slight improvement, so let's build a submission form that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_sj.fit(X_train_sj, y_train_sj)\n",
    "y_pred_sj = poly_sj.predict(X_test_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_iq.fit(X_train_iq, y_train_iq)\n",
    "y_pred_iq = poly_iq.predict(X_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate((y_pred_sj, y_pred_iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_en_sub = pd.read_csv(join(DATA_PATH, 'submission_format.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_en_sub['total_cases'] = np.round(y_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_en_sub.to_csv('../models/split_poly_en.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take aways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27.27 on leaderboard, not much of an improvement!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
